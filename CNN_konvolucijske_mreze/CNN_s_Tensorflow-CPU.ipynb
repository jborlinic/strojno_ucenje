{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Konvolucijska nevronska mreža in Tensorboard\n",
    "V Januarju 2017 je Google priredil dogodek Tensorflow development summit, \n",
    "konferenco za razvijalce za knjižnico Tensorflow.  \n",
    "Na tem dogodku so Googlovi znanstveniki predstavili delovanje raznoraznih podknjižnic knjižnice Tensorflow na \n",
    "zanimivih projektih, ki jih Google sofinancira.\n",
    "\n",
    "Med temi je zelo zanimiva predstavitev orodja Tensorboard, ([predstavitev si lahko ogledate na youtubu](https://www.youtube.com/watch?v=eBbEDRsCmv4)), ki je namenjeno vizualizaciji strojnega učenja in pregledu nad modelom. Tukaj sem poizkušal sprogramirati podobno kodo, ki jo ima Dandelion Mane. [Njegov github](https://gist.github.com/dandelionmane/4f02ab8f1451e276fea1f165a20336f1#file-mnist-py).\n",
    "\n",
    "Za primer uporabe Tensorboarda je spodaj implementiran klasifikator ročno zapisanih števil za nabor podatkov [MNIST handwritten digits](http://yann.lecun.com/exdb/mnist/). To je zelo znan nabor podatkov, ki se uporablja kot merilo, za raznorazne slikovne klasifikatorje. Tukaj je uporabljen CNN ali konvolucijski klasifikator ([dober opis](http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/)), ki doseže natančnost __0.99314%__ na testnem naboru povezanega [tekmovanja na spletnem portalu Kaggle](https://www.kaggle.com/c/digit-recognizer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../.datasets/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting ../.datasets/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ../.datasets/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../.datasets/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "\n",
    "LOG_DIR = 'log/'\n",
    "DATA_DIR = '../.datasets/mnist/'\n",
    "\n",
    "# knjižnica Tensorflow ima implementirano posebno funkcijo za pridobitev nabora podatkov MNIST\n",
    "# podatke shrani v \"train_dir\"\n",
    "mnist = tf.contrib.learn.datasets.mnist.read_data_sets(train_dir=DATA_DIR, one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definicija plasti, ki jih potrebujemo za model\n",
    "### Konvolucijska sloj\n",
    "Konvolucijski sloj je sestavljena iz konvolucije in aktivacijske funkcije.  \n",
    "Za konvolucijo potrebujemo uteži, ki predstavljajo konvolucijska jedra, velikosti 5x5.  \n",
    "Ta jedra predstavljajo vmesne filtre, ki skupaj predstavljajo karto značilnostni (ang. _feature map_).  \n",
    "Samo konvolucijo izvedemo s funkcijo conv2d knjižnice Tensorflow. Pridobljeni karti značilnosti še prištejemo \n",
    "pristranskost (ang. _bias_) in na koncu še izračunamo vrednosti aktivacijske funkcije za pridobljeno \n",
    "matriko.  \n",
    "Pri konvoluciji se uporablja princip pridobivanja značilnosti nato zmanjševanje dimenzije in ponovitve. To \n",
    "zmanjševanje dimenzije storimo z maksimalnim združevanjem (ang. _max pooling_). Ta pristop uporabimo tudi spodaj.\n",
    "\n",
    "Tako konvolucijski sloj prejme vektor oblike  \n",
    "(št. primerov, št. pikslov osi x, št. pikslov osi y, št. obstoječih kart značilnosti)  \n",
    "atribut size_in = št. obstoječih kart značilnosti  \n",
    "sloj vrne vektor oblike  \n",
    "(št. primerov, (št. pikslov osi x) / 2, (št. pikslov osi y) / 2, size_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_layer(input, size_in, size_out, name=\"conv\"):\n",
    "    \"\"\"\n",
    "    Sloj, ki izvede konvolucijo slik input. Iz \"size_in\" števila jeder priredi \"size_out\" število jeder.\n",
    "    Hkrati tudi zmanjša dimenzijo slik (faktor 2) s pomočjo maksimalnega združevanja. \n",
    "    oblika vhodnih podatkov mora biti: \n",
    "        - input (št. primerov, dim x, dim y, size_in)\n",
    "        - size_in št. obstoječih jeder\n",
    "        - size_out št. jeder izhodne matrike\n",
    "    \n",
    "    Funkcija s pomočjo tf.name_scope in tf.summary.histogram beleži vrednosti uporabljenih spremenljivk.\n",
    "    \"\"\"\n",
    "    with tf.name_scope(name):\n",
    "        w = tf.Variable(tf.truncated_normal([5, 5, size_in, size_out], stddev=0.1), name=\"W\")\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"b\")\n",
    "        conv = tf.nn.conv2d(input, w, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "        act = tf.nn.relu(conv + b)\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"activations\", act)\n",
    "        return tf.nn.max_pool(act, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polno-povezan sloj\n",
    "Polno-povezan sloj je osnovni sloj nevronskih mrež. Predstavlja sloj n-tih nevronov, ki so polno povezani \n",
    "s prejšnjim in naslednjim slojem. To je v bistvu množenje z matriko uteži oblike \n",
    "(št. nevronov prejšnje plasti, št. nevronov naslednje plasti).  \n",
    "Zraven produkta se prišteje še pristranskost in izračuna vrednost aktivacijske funkcije."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fc_layer(input, size_in, size_out, name=\"fc\"):\n",
    "    \"\"\"\n",
    "    Sloj, ki implementira osnovni nivo nevronskih mrež. \n",
    "    Vhodni podatki:\n",
    "        - input oblike (št. primerov, št. lastnosti)\n",
    "        - size_in predstavlja št. lastnosti\n",
    "        - size_out predstavlje št. lastnosti, ki jih ima izhodna matrika\n",
    "    \n",
    "    Funkcija s pomočjo tf.name_scope in tf.summary.histogram beleži vrednosti uporabljenih spremenljivk.\n",
    "    \"\"\"\n",
    "    with tf.name_scope(name):\n",
    "        w = tf.Variable(tf.truncated_normal([size_in, size_out], stddev=0.1), name=\"W\")\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"b\")\n",
    "        act = tf.nn.relu(tf.matmul(input, w) + b)\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"activations\", act)\n",
    "        return act"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Osipni sloj\n",
    "Osipni sloj predstavlja verjetnostna vrata, ki skozi spustijo le vrednosti določenih nevronov iz prejšnjih slojev.\n",
    "Upoštevamo verjetnost P(Nevron n spustimo skozi) = 0.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dropout_layer(input, keep_probability, name=\"dropout\"):\n",
    "    \"\"\"\n",
    "    Osipni sloj ne spreminja velikosti vhodne matrike, spremeni (razvrednoti) le nek delež vrednosti znotraj \n",
    "    matrike. Posamezno celico ohrani z verjetnostjo keep_probability.\n",
    "    \"\"\"\n",
    "    with tf.name_scope(name):\n",
    "        do = tf.nn.dropout(input, keep_probability)\n",
    "        tf.summary.histogram(\"dropout\", do)\n",
    "        return do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "Ta vaja je v osnovi bila sestavljena kot primer uporabe orodja Tensorboard, zato je tudi model sestavljen tako, da \n",
    "ima uporabnik možnost nastaviti, koliko posameznih slojev se uporabi v modelu.  \n",
    "V osnovi so konvolucijski modeli sestavljeni iz dveh delov, konvolucijskega dela in klasifikatorja.  \n",
    "Konvolucijski del je sestavljen iz 1-k konvolucijskih slojev (konvolucija, aktivacija, maks združevanje)  \n",
    "nato dobljeno matriko spremenimo v dvo-dimenzionalno (št. primerov, št. dobljenih lastnosti) nato jo s \n",
    "polno-povezanimi sloji zmanjšujemo in s tem klasificiramo v n razredov (v tem primeru v 10 razredov)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mnist_model(learning_rate, numberOfSteps, use_two_conv, use_two_fc, hparam_str, loadModel, writeResults):\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    # Postavitev ogrodja za vhodne podatke oblike (št. primerov, 784), \n",
    "    # saj so slike nabora podatkov MNIST velikosti 28 x 28 = 784\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784], name=\"x\")\n",
    "    \n",
    "    # preoblikuje vhodno matriko v 4-D matriko, ki jo potrebujemo za konvolucijo.\n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    \n",
    "    # Shrani 5 vhodnih slik za izris s pomočjo Tensorboarda\n",
    "    tf.summary.image(\"input\", x_image, 5)\n",
    "    \n",
    "    # Postavitev ogrodja za primerjalni kriterij \n",
    "    # y posamezne slike je razred, v katerega želimo, da jo naš model klasificira\n",
    "    y = tf.placeholder(tf.float32, shape=[None, 10], name=\"labels\")\n",
    "    \n",
    "    # Na podlagi vrednosti use_two_conv (True/False) sestavi prvi del modela\n",
    "    if use_two_conv:\n",
    "        conv1 = conv_layer(x_image, 1, 32, \"conv1\")\n",
    "        conv_output = conv_layer(conv1, 32, 64, \"conv2\")\n",
    "    \n",
    "\n",
    "    else:\n",
    "        conv1 = conv_layer(x_image, 1, 64, \"conv1\")\n",
    "        conv_output = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "    \n",
    "    # Pomožne matrike za izris naučenih kart značilnosti z orodjem Tensorboard\n",
    "    conv_image = tf.reshape(tf.slice(conv_output, [0,0,0,0], [1,7,7,64]), [64,7,7,1])\n",
    "    \n",
    "    tf.summary.image(\"conv_output\", conv_image, 64)\n",
    "    \n",
    "    # Vmesni sloj, ki pretvori 4-D matriko v 2-D matriko za klasifikacijski del modela\n",
    "    flattened = tf.reshape(conv_output, [-1, 7 * 7 * 64])\n",
    "    \n",
    "    # Na podlagi vrednosti use_two_fc (True/False) sestavi drugi del modela\n",
    "    if use_two_fc:\n",
    "        fc1 = fc_layer(flattened, 7 * 7 * 64, 1024, \"fc1\")\n",
    "        do = dropout_layer(fc1, 0.5)\n",
    "        logits = fc_layer(do, 1024, 10, \"fc2\")\n",
    "\n",
    "    else:\n",
    "        logits = fc_layer(flattened, 7 * 7 * 64, 10, \"fc1\")\n",
    "    \n",
    "    # Pomožni vektor za izpis klasifikacije slik.\n",
    "    output = tf.argmax(logits, 1)\n",
    "    \n",
    "    # Kriterijska funkcija in okvir za izpis z orodjem Tensorboard\n",
    "    with tf.name_scope('xent'):\n",
    "        xent = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y), name=\"x_ent\")\n",
    "        tf.summary.scalar('cross_entropy', xent)\n",
    "    \n",
    "    # Definicija optimizatorja\n",
    "    with tf.name_scope('train'):\n",
    "        train_step = tf.train.AdamOptimizer(learning_rate).minimize(xent)\n",
    "    \n",
    "    # Definicija metrik za učenje in validacijo modela\n",
    "    with tf.name_scope('accuracy'):\n",
    "        correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        tf.summary.scalar(\"accuracy\", accuracy)\n",
    "  \n",
    "    # Knjižnica Tensorflow deluje asinhrono glede na izvajanje programa. \n",
    "    # Zato potrebujemo posebno sejo znotraj katere učimo naš model.\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    # S to vrstico združimo vso shranjevanje/beleženje sprotnih podatkov, \n",
    "    # ki jih bomo kasneje izrisali z orodjem Tensorboard\n",
    "    merged_summary = tf.summary.merge_all()\n",
    "    \n",
    "    # Definicija zapisovalnika za orodje Tensorboard\n",
    "    writer = tf.summary.FileWriter(LOG_DIR + hparam_str)\n",
    "    \n",
    "    # Inicializacija celotnega modela znotraj seje\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Definicija shranjevalca modela\n",
    "    saver = tf.train.Saver()\n",
    "    checkpointName = LOG_DIR + hparam_str + '/myMNIST_Model'\n",
    "    \n",
    "    # Ta del kode preveri, če obstaja kakšna že shranjena iteracija našega modela in jo poizkuša naložiti.\n",
    "    if loadModel:\n",
    "        print('Trying to load previous model from: %s' %(LOG_DIR + hparam_str + '/'))\n",
    "    try: \n",
    "        f = open(LOG_DIR + hparam_str + '/checkpoint', 'r')\n",
    "        cp_path = f.readline()\n",
    "        f.close()\n",
    "        cp_path = cp_path[cp_path.find('\"')+1 : cp_path.rfind('\"')]\n",
    "\n",
    "        saver.restore(sess, cp_path)\n",
    "        print('Model succesfully restored from: %s.' %(cp_path))\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print('Can not load model: no checkpoint found.')\n",
    "    \n",
    "    # S pomočjo zapisovalnika izrišemo graf našega modela.\n",
    "    writer.add_graph(sess.graph)\n",
    "    \n",
    "    # For zanka, znotraj katere učimo naš model.\n",
    "    start_time = time.clock()\n",
    "    for i in range(numberOfSteps):\n",
    "        batch = mnist.train.next_batch(100)\n",
    "        # Vsako 5. iteracijo zapišemo vse spremenljivke, ki jih nadzorujemo\n",
    "        if i % 5 == 0:\n",
    "            s = sess.run(merged_summary, feed_dict={x: batch[0], y: batch[1]})\n",
    "            writer.add_summary(s, i)\n",
    "            \n",
    "        \n",
    "        # Vsako 500. iteracijo izpišemo učno natančnost našega modela\n",
    "        if i % 500 == 0:\n",
    "            [train_accuracy] = sess.run([accuracy], feed_dict={x: batch[0], y: batch[1]})\n",
    "            print(\"Step %d, training accuracy %g\" %(i, train_accuracy))\n",
    "            print(\"Time from start:\", round(time.clock() - start_time))\n",
    "        \n",
    "        # Vsako 10000. iteracijo shranimo kontrolno točko. Na tej točki shranimo celoten model.\n",
    "        if i % 10000 == 0 and i > 0:\n",
    "            print('Saving checkpoint.')\n",
    "            saver.save(sess, checkpointName, global_step=i)\n",
    "        \n",
    "        # Vsako 4000. iteracijo zmanjšamo učno stopnjo, tukaj zagotovimo t.i. razpad učne stopnje \n",
    "        #                                                                    (ang. learning rate decay).\n",
    "        if i % 4000 == 0:\n",
    "            learning_rate = learning_rate / 10\n",
    "        \n",
    "        # Učni korak.\n",
    "        sess.run(train_step, feed_dict={x: batch[0], y: batch[1]})\n",
    "\n",
    "    # Po učnem procesu še zapišemo klasifikacijo testnega nabora podatkov za tekmovanje na Kaggle.\n",
    "    if writeResults:\n",
    "        testData = pd.read_csv(DATA_DIR + 'test.csv')\n",
    "\n",
    "        outputData = pd.Series()\n",
    "\n",
    "        for i in range(280):\n",
    "            outputPart = pd.Series(sess.run(output, feed_dict={\n",
    "                        x: testData[i*100 : i*100 + 100]}))\n",
    "\n",
    "            outputData = outputData.append(outputPart, ignore_index=True)\n",
    "\n",
    "        outputData.index = outputData.index + 1 #indexes start with 1\n",
    "        outputData.name = 'Label'\n",
    "        outputData.to_csv(LOG_DIR + hparam_str + '/output.csv', \n",
    "                          index_label='ImageId', header=True)\n",
    "        print('Output saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dodatne funkcije\n",
    "Spodnji funkciji (setLogDir, make_hparam_string) sta v pomoč testiranju modelov s različnim številom \n",
    "konvolucijskih in polno-povezanih slojev. Vsakemu sestavijo unikaten niz, ki nato predstavlja direktorij \n",
    "posameznega modela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setLogDir(newRun):\n",
    "    \"\"\"\n",
    "    Pri testiranju modelov in večkratnem zaganjanju pri manjših spremembah se pojavi težava s ogromnim številom \n",
    "    zapisov v direktoriju log/. Zato uporabimo to funkcijo, ki brez fizičnih sprememb direktorija ustvari nov \n",
    "    direktorij za vsak nov zagon programa.\n",
    "    Seveda to ni zaželjeno, ko želimo dodatno učiti obstoječe modele, zato funkcija prejme vrednost True, ko želimo \n",
    "    nov zagon in False, ko želimo nadaljevati učenje obstoječih modelov.\n",
    "    \"\"\"\n",
    "    try: \n",
    "        f = open(LOG_DIR + 'runNumber', 'r')\n",
    "        runNumber = f.read();\n",
    "        if newRun:\n",
    "            runNumber = str(int(runNumber) + 1)\n",
    "        \n",
    "        f.close()\n",
    "        f = open(LOG_DIR + 'runNumber', 'w')\n",
    "        f.write(runNumber)\n",
    "        f.close()\n",
    "        \n",
    "        return runNumber + '/'\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        f = open(LOG_DIR + 'runNumber', 'w')\n",
    "        f.write('0');\n",
    "        f.close()\n",
    "\n",
    "        return setLogDir(newRun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_hparam_string(learning_rate, use_two_fc, use_two_conv, runNumber):\n",
    "    \"\"\"\n",
    "    Strojno učenje je proces testiranja različnih oblik modela s pomočjo medsebojnega primerjanja.\n",
    "    Ta funkcija (in rahlo dopolnjen program) omogočata delno avtomatizacijo te primerjave.\n",
    "    \n",
    "    Funkcija prejme vrednosti, ki jih spreminjamo med posameznimi modeli in na podlagi njih sestavi\n",
    "    hiper-parameter modela. To je, unikaten ključ posameznega modela, ki ga uporabljamo kot ime modela in\n",
    "    direktorija v katerega ga shranimo ter zapisujemo sprotno beleženje spremenljivk modela.\n",
    "    \"\"\"\n",
    "    fc = 1\n",
    "    conv = 1\n",
    "    if use_two_conv:\n",
    "        conv += 1\n",
    "\n",
    "    if use_two_fc:\n",
    "        fc += 1\n",
    "\n",
    "    return '%slr_%.0E__fc_%d__conv_%d' %(runNumber, learning_rate, fc, conv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main\n",
    "V funkciji main nastavimo spremenljivke in s tem funkcije, ki jih žečlimo, da se izvedejo tekom izvajanja programa.\n",
    "Nato kličemo funkcijo mnist_model, ki sestavi določen model in ga nato uči neko določeno število korakov.  \n",
    "Funkcija tudi zapisuje sprotno stanje učenja (ang. _logs_) v primerni direktorij, določen z nizom pridobljenim z zgornjima funkcijama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can not load model: no checkpoint found.\n",
      "Step 0, training accuracy 0.13\n",
      "Time from start: 0\n",
      "Step 500, training accuracy 0.11\n",
      "Time from start: 164\n",
      "Step 1000, training accuracy 0.1\n",
      "Time from start: 331\n",
      "Can not load model: no checkpoint found.\n",
      "Step 0, training accuracy 0.07\n",
      "Time from start: 0\n",
      "Step 500, training accuracy 0.1\n",
      "Time from start: 110\n",
      "Step 1000, training accuracy 0.1\n",
      "Time from start: 221\n",
      "Can not load model: no checkpoint found.\n",
      "Step 0, training accuracy 0.09\n",
      "Time from start: 0\n",
      "Step 500, training accuracy 0.29\n",
      "Time from start: 131\n",
      "Step 1000, training accuracy 0.35\n",
      "Time from start: 260\n",
      "Can not load model: no checkpoint found.\n",
      "Step 0, training accuracy 0.14\n",
      "Time from start: 0\n",
      "Step 500, training accuracy 0.36\n",
      "Time from start: 88\n",
      "Step 1000, training accuracy 0.45\n",
      "Time from start: 177\n",
      "Can not load model: no checkpoint found.\n",
      "Step 0, training accuracy 0.11\n",
      "Time from start: 0\n",
      "Step 500, training accuracy 0.9\n",
      "Time from start: 161\n",
      "Step 1000, training accuracy 0.97\n",
      "Time from start: 321\n",
      "Can not load model: no checkpoint found.\n",
      "Step 0, training accuracy 0.13\n",
      "Time from start: 0\n",
      "Step 500, training accuracy 0.84\n",
      "Time from start: 106\n",
      "Step 1000, training accuracy 0.97\n",
      "Time from start: 213\n",
      "Can not load model: no checkpoint found.\n",
      "Step 0, training accuracy 0.04\n",
      "Time from start: 0\n",
      "Step 500, training accuracy 0.6\n",
      "Time from start: 128\n",
      "Step 1000, training accuracy 0.71\n",
      "Time from start: 257\n",
      "Can not load model: no checkpoint found.\n",
      "Step 0, training accuracy 0.11\n",
      "Time from start: 0\n",
      "Step 500, training accuracy 0.75\n",
      "Time from start: 84\n",
      "Step 1000, training accuracy 0.91\n",
      "Time from start: 168\n",
      "Can not load model: no checkpoint found.\n",
      "Step 0, training accuracy 0.13\n",
      "Time from start: 0\n",
      "Step 500, training accuracy 0.11\n",
      "Time from start: 161\n",
      "Step 1000, training accuracy 0.18\n",
      "Time from start: 322\n",
      "Can not load model: no checkpoint found.\n",
      "Step 0, training accuracy 0.07\n",
      "Time from start: 0\n",
      "Step 500, training accuracy 0.26\n",
      "Time from start: 107\n",
      "Step 1000, training accuracy 0.4\n",
      "Time from start: 217\n",
      "Can not load model: no checkpoint found.\n",
      "Step 0, training accuracy 0.17\n",
      "Time from start: 0\n",
      "Step 500, training accuracy 0.43\n",
      "Time from start: 137\n",
      "Step 1000, training accuracy 0.48\n",
      "Time from start: 269\n",
      "Can not load model: no checkpoint found.\n",
      "Step 0, training accuracy 0.11\n",
      "Time from start: 0\n",
      "Step 500, training accuracy 0.35\n",
      "Time from start: 86\n",
      "Step 1000, training accuracy 0.37\n",
      "Time from start: 156\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def main():\n",
    "    # Ali želimo naložiti obstoječ model?\n",
    "    loadModel = False\n",
    "    \n",
    "    # Ali želimo klasificirati testni nabor podatkov?\n",
    "    writeResults = False\n",
    "    \n",
    "    # Zaporedno število, ki ločuje posamezne zagone programa.\n",
    "    runNumber = setLogDir(not loadModel)\n",
    "    \n",
    "    # Parametri posameznih modelov, ki jih želimo sestaviti in primerjati s programom.\n",
    "    numberOfSteps = 1001\n",
    "    learning_rates = [1E-3, 1E-4, 1E-5]\n",
    "    two_fc = [True, False]\n",
    "    two_conv = [True, False]\n",
    "\n",
    "    # Klici funkcije za izgradnjo in učenje modelov s vsemi kombinacij zgornjih parametrov\n",
    "    for learning_rate in learning_rates:\n",
    "        for use_two_fc in two_fc:\n",
    "              for use_two_conv in two_conv:\n",
    "                hparam_str = make_hparam_string(learning_rate, use_two_fc, use_two_conv, runNumber)\n",
    "    \n",
    "                mnist_model(learning_rate, \n",
    "                            numberOfSteps, \n",
    "                            use_two_conv, \n",
    "                            use_two_fc, \n",
    "                            hparam_str, \n",
    "                            loadModel, \n",
    "                            writeResults)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
