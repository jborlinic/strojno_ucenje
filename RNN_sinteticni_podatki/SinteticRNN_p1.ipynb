{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Osnovna ponavljajoča nevronaska mreža (_ang. RNN-Recurrent Neural Network_)\n",
    "Za začetek učenja ponavljajočih nevronskih mrež poizkušajmo slediti in implementirati osnovni RNN po [tem tutorialu](http://r2rt.com/recurrent-neural-networks-in-tensorflow-i.html).  \n",
    "V kategorijo ponavljajočih nevronskih mrež spadajo predvsem takšne mreže, ki s pomočjo ponavljajočega izvajanja dela mreže ali ciklične povezanosti poizkušajo razumeti zaporedne lastnosti nabora podatkov. Ideja temelji na n-kratni ponovitvi RNN-celice, ki je v jedru nevronske mreže. RNN-ji so najbolj uporabni za časovno odvisne nabore podatkov, katerih osnovna lastnost je, da vsebujejo nize podatkov. RNN-celice so sestavljene tako, da te nize podatkov sprocesirajo po delih, vsak del v svoji ponovitvi. Med seboj so povezane tako, da se izhodni podatki ene ponovitve celice dodajo vhodnim podatkom naslednje ponovitve in s tem pridobimo možnost, da pomen podatkov prvega dela niza vpliva na pomen podatkov v naslednjem delu niza itn.  \n",
    "Ta osnovna ideja ponavljajočih nevronskih mrež je v zgornjem tutorialu lepo opisana in prikazana na sintetičnem naboru podatkov. Spodnja koda pa je prvi del kode, ki je nastala ob sledenju zgornji povezavi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Global config variables\n",
    "num_steps = 10 # number of truncated backprop steps ('n' in the discussion above)\n",
    "batch_size = 200\n",
    "num_classes = 2\n",
    "state_size = 4\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_data(size=1000000):\n",
    "    X = np.array(np.random.choice(2, size=(size,)))\n",
    "    Y = []\n",
    "    for i in range(size):\n",
    "        threshold = 0.5\n",
    "        if X[i-3] == 1:\n",
    "            threshold += 0.5\n",
    "        if X[i-8] == 1:\n",
    "            threshold -= 0.25\n",
    "        if np.random.rand() > threshold:\n",
    "            Y.append(0)\n",
    "        else:\n",
    "            Y.append(1)\n",
    "    return X, np.array(Y)\n",
    "\n",
    "# adapted from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/ptb/reader.py\n",
    "def gen_batch(raw_data, batch_size, num_steps):\n",
    "    raw_x, raw_y = raw_data\n",
    "    data_length = len(raw_x)\n",
    "\n",
    "    # partition raw data into batches and stack them vertically in a data matrix\n",
    "    batch_partition_length = data_length // batch_size\n",
    "    data_x = np.zeros([batch_size, batch_partition_length], dtype=np.int32)\n",
    "    data_y = np.zeros([batch_size, batch_partition_length], dtype=np.int32)\n",
    "    for i in range(batch_size):\n",
    "        data_x[i] = raw_x[batch_partition_length * i:batch_partition_length * (i + 1)]\n",
    "        data_y[i] = raw_y[batch_partition_length * i:batch_partition_length * (i + 1)]\n",
    "    # further divide batch partitions into num_steps for truncated backprop\n",
    "    epoch_size = batch_partition_length // num_steps\n",
    "\n",
    "    for i in range(epoch_size):\n",
    "        x = data_x[:, i * num_steps:(i + 1) * num_steps]\n",
    "        y = data_y[:, i * num_steps:(i + 1) * num_steps]\n",
    "        yield (x, y)\n",
    "\n",
    "def gen_epochs(n, num_steps):\n",
    "    for i in range(n):\n",
    "        yield gen_batch(gen_data(), batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Placeholders\n",
    "\"\"\"\n",
    "\n",
    "x = tf.placeholder(tf.int32, [batch_size, num_steps], name='input_placeholder')\n",
    "y = tf.placeholder(tf.int32, [batch_size, num_steps], name='labels_placeholder')\n",
    "init_state = tf.zeros([batch_size, state_size])\n",
    "\n",
    "\"\"\"\n",
    "Inputs\n",
    "\"\"\"\n",
    "\n",
    "rnn_inputs = tf.one_hot(x, num_classes)\n",
    "\n",
    "\"\"\"\n",
    "RNN\n",
    "\"\"\"\n",
    "\n",
    "cell = tf.contrib.rnn.BasicRNNCell(state_size)\n",
    "rnn_outputs, final_state = tf.nn.dynamic_rnn(cell, rnn_inputs, initial_state=init_state)\n",
    "\n",
    "\"\"\"\n",
    "Predictions, loss, training step\n",
    "\"\"\"\n",
    "\n",
    "with tf.variable_scope('softmax'):\n",
    "    W = tf.get_variable('W', [state_size, num_classes])\n",
    "    b = tf.get_variable('b', [num_classes], initializer=tf.constant_initializer(0.0))\n",
    "logits = tf.reshape(\n",
    "            tf.matmul(tf.reshape(rnn_outputs, [-1, state_size]), W) + b,\n",
    "            [batch_size, num_steps, num_classes])\n",
    "predictions = tf.nn.softmax(logits)\n",
    "\n",
    "losses = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "train_step = tf.train.AdagradOptimizer(learning_rate).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train the network\n",
    "\"\"\"\n",
    "\n",
    "def train_network(num_epochs, num_steps, state_size=4, verbose=True):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        training_losses = []\n",
    "        for idx, epoch in enumerate(gen_epochs(num_epochs, num_steps)):\n",
    "            training_loss = 0\n",
    "            training_state = np.zeros((batch_size, state_size))\n",
    "            if verbose:\n",
    "                print(\"\\nEPOCH\", idx)\n",
    "            for step, (X, Y) in enumerate(epoch):\n",
    "                tr_losses, training_loss_, input_x, rnn_out, training_state, _ = \\\n",
    "                    sess.run([losses,\n",
    "                              total_loss,\n",
    "                              rnn_inputs,\n",
    "                              rnn_outputs,\n",
    "                              final_state,\n",
    "                              train_step],\n",
    "                                  feed_dict={x:X, y:Y, init_state:training_state})\n",
    "                training_loss += training_loss_\n",
    "                if step % 100 == 0 and step > 0:\n",
    "                    if verbose:\n",
    "                        print(\"Average loss at step\", step,\n",
    "                              \"for last 250 steps:\", training_loss/100)\n",
    "                    training_losses.append(training_loss/100)\n",
    "                    training_loss = 0\n",
    "                    print(input_x[0],'\\n', rnn_out[0])\n",
    "\n",
    "    return training_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 0\n",
      "Average loss at step 100 for last 250 steps: 0.622288075089\n",
      "[[ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]] \n",
      " [[ 0.4146623  -0.54323041  0.71038729  0.75951642]\n",
      " [ 0.56690001 -0.08678813 -0.05555882 -0.8841241 ]\n",
      " [ 0.28110269  0.11736859 -0.31548217  0.85789412]\n",
      " [ 0.41539589 -0.18349363  0.62354994  0.46098316]\n",
      " [ 0.51565337 -0.32934466  0.07751327 -0.7773484 ]\n",
      " [ 0.29000697  0.35846323 -0.42353064  0.76356369]\n",
      " [ 0.38770413 -0.38119087  0.70141125  0.62229043]\n",
      " [ 0.68884724  0.55969411  0.17840759 -0.3843075 ]\n",
      " [ 0.62217927 -0.34705052  0.34672886  0.78644061]\n",
      " [ 0.73980719  0.24058397  0.23670521 -0.0478593 ]]\n",
      "Average loss at step 200 for last 250 steps: 0.528475174308\n",
      "[[ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]] \n",
      " [[ 0.59386432 -0.72460991 -0.04805132 -0.0585435 ]\n",
      " [ 0.37114593  0.25346377 -0.59148115  0.54953313]\n",
      " [ 0.14125651 -0.44088778  0.53635347  0.76610792]\n",
      " [ 0.46583948  0.65667415  0.27122527 -0.52070814]\n",
      " [ 0.65506148 -0.26405999  0.21046384  0.61720425]\n",
      " [ 0.59401202 -0.57315767 -0.17053589 -0.42973682]\n",
      " [ 0.29556537  0.10121283 -0.65860438  0.73508793]\n",
      " [ 0.00563538 -0.34784645  0.55536568  0.72420645]\n",
      " [ 0.38313371  0.69246453  0.37113625 -0.56965607]\n",
      " [ 0.64842236 -0.16420804  0.24507752  0.53027582]]\n",
      "Average loss at step 300 for last 250 steps: 0.52187699914\n",
      "[[ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]] \n",
      " [[  1.47343725e-01  -3.54377270e-01   4.81037617e-01   6.87507272e-01]\n",
      " [  3.33645046e-01   5.51364869e-02   1.22875944e-02  -7.89892793e-01]\n",
      " [  1.86159506e-01  -5.19171000e-01  -6.11091614e-01   2.62583047e-01]\n",
      " [ -2.64639467e-01   1.02409661e-01  -1.53780237e-01   6.66118979e-01]\n",
      " [ -2.10395426e-01   3.48050296e-01   6.55430853e-01  -4.51204665e-02]\n",
      " [  3.34546953e-01   5.95772266e-01   4.38059688e-01  -4.48559970e-01]\n",
      " [  6.40354276e-01  -2.32193619e-04   1.53138205e-01   3.61373365e-01]\n",
      " [  5.86561978e-01  -6.17645741e-01  -1.43674433e-01  -1.43894628e-01]\n",
      " [  3.33785206e-01   1.40713498e-01  -5.96573591e-01   6.50501847e-01]\n",
      " [ -3.58004309e-02  -7.72124469e-01   2.97954232e-01   2.94629455e-01]]\n",
      "Average loss at step 400 for last 250 steps: 0.520838411748\n",
      "[[ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]] \n",
      " [[-0.24550413  0.03169328  0.46477699 -0.72870779]\n",
      " [ 0.0607028   0.66506636 -0.17843419 -0.1546609 ]\n",
      " [ 0.02612367 -0.64488429  0.31942135  0.12533134]\n",
      " [ 0.13445751  0.69549334 -0.30019107 -0.26779023]\n",
      " [ 0.15464747 -0.33557883  0.44099811  0.70965803]\n",
      " [ 0.31876373  0.08444241  0.01493289 -0.75900996]\n",
      " [ 0.31915402  0.05796526 -0.39474663  0.65637994]\n",
      " [ 0.05695974 -0.65364879  0.23384181  0.10125589]\n",
      " [-0.03169082  0.21883777 -0.51212293 -0.58930516]\n",
      " [-0.28155243 -0.07994207 -0.02004698  0.76309216]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe0000156a0>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe012d330f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_losses = train_network(1,num_steps)\n",
    "plt.plot(training_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:jupyter-tf]",
   "language": "python",
   "name": "conda-env-jupyter-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
