{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drugi del [RNN tutoriala](http://r2rt.com/recurrent-neural-networks-in-tensorflow-i.html), ki vključuje daljše nize in s tem tudi večjo nevronsko mrežo.  \n",
    "Ta model boljše prikazuje kvaliteto in \"spomin\" ponavljajoče nevronske mreže. Saj se le daljša mreža lahko nauči daljše časovne odvisnosti.  \n",
    "S spodnjim modelom dobimo boljši občutek, kako RNN-ji delujejo in kako število ponovitev RNN-celice vpliva na natančnost rezultatov modela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Global config variables\n",
    "num_steps = 20 #number of truncated backprop steps\n",
    "batch_size = 200\n",
    "num_classes = 2\n",
    "state_size = 16\n",
    "learning_rate = 0.1\n",
    "\n",
    "\n",
    "### [timestamp, price, ammount_traded, prediction_for_next_price]\n",
    "file_name = '../data/dataT.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data(file_name):\n",
    "    return np.load(file_name)\n",
    "\n",
    "# adapted from:\n",
    "# https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/ptb/reader.py\n",
    "\n",
    "def gen_batch(raw_data, batch_size, num_steps):\n",
    "    raw_x, raw_y = raw_data\n",
    "    data_length = len(raw_x)\n",
    "    \n",
    "    # partition raw data into batches and stack them vertically in a data matrix\n",
    "    batch_partition_length = data_length // batch_size\n",
    "    data_x = np.zeros([batch_size, batch_partition_length], dtype=np.float32)\n",
    "    data_y = np.zeros([batch_size, batch_partition_length], dtype=np.float32)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        data_x[i] = raw_x[batch_partition_length * i:batch_partition_length * (i + 1)]\n",
    "        data_y[i] = raw_y[batch_partition_length * i:batch_partition_length * (i + 1)]\n",
    "    \n",
    "    # further divide batch partitions into num_steps for truncated backprop\n",
    "    epoch_size = batch_partition_length // num_steps\n",
    "    \n",
    "    for i in range(epoch_size):\n",
    "        x = data_x[:, i * num_steps: (i + 1) * num_steps]\n",
    "        y = data_y[:, i * num_steps: (i + 1) * num_steps]\n",
    "        yield(x, y)\n",
    "\n",
    "def gen_epochs(n, num_steps):\n",
    "    for i in range(n):\n",
    "        yield gen_batch(gen_data(), batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "static = False\n",
    "if(static == True):\n",
    "    \"\"\"\n",
    "    Placeholders\n",
    "    \"\"\"\n",
    "\n",
    "    x = tf.placeholder(tf.int32, [batch_size, num_steps], name='input_placeholder')\n",
    "    y = tf.placeholder(tf.int32, [batch_size, num_steps], name='labels_placeholder')\n",
    "    init_state = tf.zeros([batch_size, state_size])\n",
    "\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    \"\"\"\n",
    "\n",
    "    x_one_hot = tf.one_hot(x, num_classes)\n",
    "    rnn_inputs = tf.unstack(x_one_hot, axis=1)\n",
    "\n",
    "    \"\"\"\n",
    "    RNN\n",
    "    \"\"\"\n",
    "\n",
    "    cell = tf.contrib.rnn.BasicRNNCell(state_size)\n",
    "    rnn_outputs, final_state = tf.contrib.rnn.static_rnn(cell, rnn_inputs, initial_state=init_state)\n",
    "\n",
    "    \"\"\"\n",
    "    Predictions, loss, training step\n",
    "    \"\"\"\n",
    "\n",
    "    with tf.variable_scope('softmax'):\n",
    "        W = tf.get_variable('W', [state_size, num_classes])\n",
    "        b = tf.get_variable('b', [num_classes], initializer=tf.constant_initializer(0.0))\n",
    "    logits = [tf.matmul(rnn_output, W) + b for rnn_output in rnn_outputs]\n",
    "    predictions = [tf.nn.softmax(logit) for logit in logits]\n",
    "\n",
    "    y_as_list = tf.unstack(y, num=num_steps, axis=1)\n",
    "\n",
    "    losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label, logits=logit) for \\\n",
    "              logit, label in zip(logits, y_as_list)]\n",
    "    total_loss = tf.reduce_mean(losses)\n",
    "    train_step = tf.train.AdagradOptimizer(learning_rate).minimize(total_loss)\n",
    "\n",
    "else:\n",
    "    \"\"\"\n",
    "    Placeholders\n",
    "    \"\"\"\n",
    "\n",
    "    x = tf.placeholder(tf.int32, [batch_size, num_steps], name='input_placeholder')\n",
    "    y = tf.placeholder(tf.int32, [batch_size, num_steps], name='labels_placeholder')\n",
    "    init_state = tf.zeros([batch_size, state_size])\n",
    "\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    \"\"\"\n",
    "\n",
    "    rnn_inputs = tf.one_hot(x, num_classes)\n",
    "\n",
    "    \"\"\"\n",
    "    RNN\n",
    "    \"\"\"\n",
    "\n",
    "    cell = tf.contrib.rnn.BasicRNNCell(state_size)\n",
    "    rnn_outputs, final_state = tf.nn.dynamic_rnn(cell, rnn_inputs, initial_state=init_state)\n",
    "\n",
    "    \"\"\"\n",
    "    Predictions, loss, training step\n",
    "    \"\"\"\n",
    "\n",
    "    with tf.variable_scope('softmax'):\n",
    "        W = tf.get_variable('W', [state_size, num_classes])\n",
    "        b = tf.get_variable('b', [num_classes], initializer=tf.constant_initializer(0.0))\n",
    "    logits = tf.reshape(\n",
    "                tf.matmul(tf.reshape(rnn_outputs, [-1, state_size]), W) + b,\n",
    "                [batch_size, num_steps, num_classes])\n",
    "    predictions = tf.nn.softmax(logits)\n",
    "\n",
    "    losses = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    total_loss = tf.reduce_mean(losses)\n",
    "    train_step = tf.train.AdagradOptimizer(learning_rate).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train the network\n",
    "\"\"\"\n",
    "\n",
    "def train_network(num_epochs, num_steps, state_size=16, verbose=True):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        training_losses = []\n",
    "        for idx, epoch in enumerate(gen_epochs(num_epochs, num_steps)):\n",
    "            training_loss = 0\n",
    "            training_state = np.zeros((batch_size, state_size))\n",
    "            if verbose:\n",
    "                print(\"\\nEPOCH\", idx)\n",
    "            for step, (X, Y) in enumerate(epoch):\n",
    "                tr_losses, training_loss_, training_state, _ = \\\n",
    "                    sess.run([losses,\n",
    "                              total_loss,\n",
    "                              final_state,\n",
    "                              train_step],\n",
    "                                  feed_dict={x:X, y:Y, init_state:training_state})\n",
    "                training_loss += training_loss_\n",
    "                if step % 100 == 0 and step > 0:\n",
    "                    if verbose:\n",
    "                        print(\"Average loss at step\", step,\n",
    "                              \"for last 250 steps:\", training_loss/100)\n",
    "                    training_losses.append(training_loss/100)\n",
    "                    training_loss = 0\n",
    "\n",
    "    return training_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 0\n",
      "Average loss at step 100 for last 250 steps: 0.517540174723\n",
      "Average loss at step 200 for last 250 steps: 0.479615024924\n",
      "\n",
      "EPOCH 1\n",
      "Average loss at step 100 for last 250 steps: 0.478315629959\n",
      "Average loss at step 200 for last 250 steps: 0.468093816638\n",
      "\n",
      "EPOCH 2\n",
      "Average loss at step 100 for last 250 steps: 0.469838148654\n",
      "Average loss at step 200 for last 250 steps: 0.463203283846\n",
      "\n",
      "EPOCH 3\n",
      "Average loss at step 100 for last 250 steps: 0.467783700526\n",
      "Average loss at step 200 for last 250 steps: 0.460989165008\n",
      "\n",
      "EPOCH 4\n",
      "Average loss at step 100 for last 250 steps: 0.46661487788\n",
      "Average loss at step 200 for last 250 steps: 0.460087717175\n",
      "\n",
      "EPOCH 5\n",
      "Average loss at step 100 for last 250 steps: 0.465504909754\n",
      "Average loss at step 200 for last 250 steps: 0.45874121815\n",
      "\n",
      "EPOCH 6\n",
      "Average loss at step 100 for last 250 steps: 0.464618277252\n",
      "Average loss at step 200 for last 250 steps: 0.458166795075\n",
      "\n",
      "EPOCH 7\n",
      "Average loss at step 100 for last 250 steps: 0.464298971891\n",
      "Average loss at step 200 for last 250 steps: 0.458637823462\n",
      "\n",
      "EPOCH 8\n",
      "Average loss at step 100 for last 250 steps: 0.46342173785\n",
      "Average loss at step 200 for last 250 steps: 0.457668612599\n",
      "\n",
      "EPOCH 9\n",
      "Average loss at step 100 for last 250 steps: 0.464295051694\n",
      "Average loss at step 200 for last 250 steps: 0.458488462269\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1df8195cf8>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1e42acd5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_losses = train_network(10,num_steps)\n",
    "plt.plot(training_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_data(size=1000000):\n",
    "    X = np.array(np.random.choice(2, size=(size,)))\n",
    "    Y = []\n",
    "    for i in range(size):\n",
    "        threshold = 0.5\n",
    "        if X[i-3] == 1:\n",
    "            threshold += 0.5\n",
    "        if X[i-8] == 1:\n",
    "            threshold -= 0.25\n",
    "        if np.random.rand() > threshold:\n",
    "            Y.append(0)\n",
    "        else:\n",
    "            Y.append(1)\n",
    "    return X, np.array(Y)\n",
    "\n",
    "# adapted from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/ptb/reader.py\n",
    "def gen_batch(raw_data, batch_size, num_steps):\n",
    "    raw_x, raw_y = raw_data\n",
    "    data_length = len(raw_x)\n",
    "\n",
    "    # partition raw data into batches and stack them vertically in a data matrix\n",
    "    batch_partition_length = data_length // batch_size\n",
    "    data_x = np.zeros([batch_size, batch_partition_length], dtype=np.int32)\n",
    "    data_y = np.zeros([batch_size, batch_partition_length], dtype=np.int32)\n",
    "    for i in range(batch_size):\n",
    "        data_x[i] = raw_x[batch_partition_length * i:batch_partition_length * (i + 1)]\n",
    "        data_y[i] = raw_y[batch_partition_length * i:batch_partition_length * (i + 1)]\n",
    "    # further divide batch partitions into num_steps for truncated backprop\n",
    "    epoch_size = batch_partition_length // num_steps\n",
    "\n",
    "    for i in range(epoch_size):\n",
    "        x = data_x[:, i * num_steps:(i + 1) * num_steps]\n",
    "        y = data_y[:, i * num_steps:(i + 1) * num_steps]\n",
    "        yield (x, y)\n",
    "\n",
    "def gen_epochs(n, num_steps):\n",
    "    for i in range(n):\n",
    "        yield gen_batch(gen_data(), 200, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = gen_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "batch = gen_epochs(4, 5)\n",
    "for idx,epoch in enumerate(batch):\n",
    "    print(idx)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:jupyter-tf]",
   "language": "python",
   "name": "conda-env-jupyter-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
